{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d1i2OO8P0C3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Tree / Boosting models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = '/kaggle/input/mock-test-2-mse-2/train.csv'\n",
        "TEST_PATH  = '/kaggle/input/mock-test-2-mse-2/test.csv'\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df  = pd.read_csv(TEST_PATH)"
      ],
      "metadata": {
        "id": "dIOpnu71P6qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "LxUVw5YDP9Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COL = 'Status' # Change to target col\n",
        "ID_COL     = 'id'"
      ],
      "metadata": {
        "id": "c6_SK0tjQA_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if train_df[TARGET_COL].isna().any():\n",
        "    target_mode = train_df[TARGET_COL].mode(dropna=True)[0]\n",
        "    train_df[TARGET_COL] = train_df[TARGET_COL].fillna(target_mode)"
      ],
      "metadata": {
        "id": "2PIfouJZQCG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "-jaKJkgOQFaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "zWwQ8gwYQHt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(train_df[TARGET_COL])\n",
        "\n",
        "X = train_df.drop(columns=[c for c in [TARGET_COL, ID_COL] if c in train_df.columns])\n",
        "test_ids = test_df[ID_COL].copy()\n",
        "X_test = test_df.drop(columns=[ID_COL])"
      ],
      "metadata": {
        "id": "kZXXbJ8EQKkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X.select_dtypes(include=['int64','float64']).columns\n",
        "cat_cols = X.select_dtypes(exclude=['int64','float64']).columns"
      ],
      "metadata": {
        "id": "mHqgJLRMQNp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_cols),\n",
        "        ('cat', categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Smf7dPcGQP1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cap_outliers(df, cols, lower=1, upper=99):\n",
        "    \"\"\"Caps outliers using percentile-based winsorization.\"\"\"\n",
        "    df = df.copy()\n",
        "    for c in cols:\n",
        "        lo, hi = df[c].quantile([lower/100, upper/100])\n",
        "        df[c] = df[c].clip(lo, hi)\n",
        "    return df\n",
        "\n",
        "# Apply capping ONLY on feature matrices (never on target or id)\n",
        "X = cap_outliers(X, num_cols)\n",
        "X_test = cap_outliers(X_test, num_cols)"
      ],
      "metadata": {
        "id": "FTy9RdhQQThO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_cols[:6]:  # limit to avoid clutter\n",
        "    plt.figure(figsize=(5, 2))\n",
        "    sns.boxplot(x=X[col])\n",
        "    plt.title(f\"Boxplot: {col}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xpZDb7unQWMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(num_cols) > 1:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    corr = X[num_cols].corr()\n",
        "    sns.heatmap(corr, cmap='coolwarm', center=0)\n",
        "    plt.title(\"Correlation Matrix (Numerical Features)\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "P_28siqkQYwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(num_cols) <= 5:\n",
        "    sns.pairplot(train_df[num_cols.tolist() + [TARGET_COL]], hue=TARGET_COL)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0KVuaH5-QbyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(\n",
        "    n_estimators=600,\n",
        "    criterion=\"log_loss\",\n",
        "    max_depth=8,\n",
        "    min_samples_split=25,\n",
        "    min_samples_leaf=15,\n",
        "    max_features=0.7,\n",
        "    class_weight=\"balanced\",\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        "),\n",
        "\n",
        "    'LightGBM': lgb.LGBMClassifier(\n",
        "    objective=\"multiclass\",\n",
        "    metric=\"multi_logloss\",\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=800,\n",
        "    num_leaves=15,\n",
        "    max_depth=5,\n",
        "\n",
        "    min_child_samples=50,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.7,\n",
        "\n",
        "    reg_alpha=1.5,\n",
        "    reg_lambda=3.0,\n",
        "\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose = -1\n",
        "\n",
        "),\n",
        "\n",
        "    'XGBoost': xgb.XGBClassifier(\n",
        "    objective=\"multi:softprob\",\n",
        "    eval_metric=\"mlogloss\",\n",
        "\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=700,\n",
        "    max_depth=4,\n",
        "\n",
        "    min_child_weight=10,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.7,\n",
        "\n",
        "    reg_alpha=1.5,\n",
        "    reg_lambda=3.0,\n",
        "\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "zq8KAzoiQenp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FOR LARGE DATASET >3k\n",
        "\n",
        "# models = {\n",
        "#     'RandomForest': RandomForestClassifier(\n",
        "#     n_estimators=1000,\n",
        "#     criterion=\"log_loss\",\n",
        "#     max_depth=12,\n",
        "#     min_samples_split=15,\n",
        "#     min_samples_leaf=8,\n",
        "#     max_features=\"sqrt\",\n",
        "#     class_weight=\"balanced\",\n",
        "#     bootstrap=True,\n",
        "#     n_jobs=-1,\n",
        "#     random_state=42\n",
        "# ),\n",
        "\n",
        "#     'LightGBM': lgb.LGBMClassifier(\n",
        "#     objective=\"multiclass\",\n",
        "#     metric=\"multi_logloss\",\n",
        "\n",
        "#     learning_rate=0.03,\n",
        "#     n_estimators=3000,\n",
        "#     num_leaves=31,\n",
        "#     max_depth=6,\n",
        "\n",
        "#     min_child_samples=30,\n",
        "#     subsample=0.8,\n",
        "#     subsample_freq=1,\n",
        "#     colsample_bytree=0.8,\n",
        "\n",
        "#     reg_alpha=1.0,\n",
        "#     reg_lambda=2.0,\n",
        "\n",
        "#     class_weight=\"balanced\",\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1\n",
        "\n",
        "# ),\n",
        "\n",
        "#     'XGBoost': xgb.XGBClassifier(\n",
        "#     objective=\"multi:softprob\",\n",
        "#     eval_metric=\"mlogloss\",\n",
        "\n",
        "#     learning_rate=0.03,\n",
        "#     n_estimators=2500,\n",
        "#     max_depth=6,\n",
        "\n",
        "#     min_child_weight=5,\n",
        "#     subsample=0.8,\n",
        "#     colsample_bytree=0.8,\n",
        "\n",
        "#     reg_alpha=1.0,\n",
        "#     reg_lambda=2.0,\n",
        "\n",
        "#     tree_method=\"hist\",\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "# }\n"
      ],
      "metadata": {
        "id": "WAM_WGV1YzQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "from sklearn.base import clone\n",
        "\n",
        "for name, model in models.items():\n",
        "    losses = []\n",
        "    for train_idx, val_idx in skf.split(X, y):\n",
        "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        # IMPORTANT: clone model for each fold (fixes LightGBM/XGBoost feature mismatch)\n",
        "        model_clone = clone(model)\n",
        "\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('model', model_clone)\n",
        "        ])\n",
        "\n",
        "        pipe.fit(X_tr, y_tr)\n",
        "        val_pred = pipe.predict_proba(X_val)\n",
        "        losses.append(log_loss(y_val, val_pred))\n",
        "\n",
        "    results[name] = np.mean(losses)\n",
        "    print(f\"{name} CV LogLoss: {results[name]:.5f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "haOVC6umQiwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_models = sorted(results.items(), key=lambda x: x[1])\n",
        "\n",
        "best_model_name, best_score = sorted_models[0]\n",
        "second_model_name, second_score = sorted_models[1]\n",
        "\n",
        "best_model = models[best_model_name]\n",
        "second_model = models[second_model_name]\n",
        "\n",
        "print(f\"Top-2 Models Selected:\")\n",
        "print(f\"{best_model_name} (LogLoss: {best_score:.5f})\")\n",
        "print(f\"{second_model_name} (LogLoss: {second_score:.5f})\")"
      ],
      "metadata": {
        "id": "fChxpkuaaiyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CALIBRATION_FOR_LOGLOSS = True  # keep True for log-loss competitions\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "pipelines = {}\n",
        "\n",
        "for name, model in [(best_model_name, best_model), (second_model_name, second_model)]:\n",
        "    if USE_CALIBRATION_FOR_LOGLOSS:\n",
        "        calibrated_model = CalibratedClassifierCV(\n",
        "            estimator=model,\n",
        "            method='isotonic',\n",
        "            cv=3\n",
        "        )\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('model', calibrated_model)\n",
        "        ])\n",
        "    else:\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('model', model)\n",
        "        ])\n"
      ],
      "metadata": {
        "id": "xxswtekQakJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(X, y)\n",
        "pipelines[name] = pipe"
      ],
      "metadata": {
        "id": "Q4VzpvLEQtxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUBMIT_PROBABILITIES = True   # True → log_loss submission\n",
        "SUBMIT_LABELS        = False  # True → accuracy / precision submission"
      ],
      "metadata": {
        "id": "kn43vhyyQyyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1, W2 = 0.65, 0.35\n",
        "\n",
        "proba_1 = pipelines[best_model_name].predict_proba(X_test)\n",
        "proba_2 = pipelines[second_model_name].predict_proba(X_test)\n",
        "\n",
        "y_pred_prob = W1 * proba_1 + W2 * proba_2\n",
        "y_pred_labels_enc= pipelines[best_model_name].predict(X_test)"
      ],
      "metadata": {
        "id": "9RsGeYZtQ0-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SUBMIT_PROBABILITIES:\n",
        "    # ---- GET ENCODED CLASS ORDER FROM MODEL ----\n",
        "    # predict_proba columns follow encoded class order: 0..K-1\n",
        "    n_classes = y_pred_prob.shape[1]\n",
        "    encoded_classes = np.arange(n_classes)\n",
        "\n",
        "    # ---- INVERSE TRANSFORM TO ORIGINAL LABELS ----\n",
        "    original_labels = label_encoder.inverse_transform(encoded_classes)\n",
        "\n",
        "    submission_cols = [f\"{TARGET_COL}_{cls}\" for cls in original_labels]\n",
        "\n",
        "    submission = pd.DataFrame(y_pred_prob, columns=submission_cols)\n",
        "    submission.insert(0, ID_COL, test_ids if test_ids is not None else range(len(submission)))\n",
        "\n",
        "    # ---- REORDER EXACTLY LIKE sample_submission.csv IF AVAILABLE ----\n",
        "    # try:\n",
        "    #     sample_sub = pd.read_csv('sample_submission.csv')\n",
        "    #     ordered_cols = sample_sub.columns.tolist()\n",
        "    #     submission = submission[ordered_cols]\n",
        "    #     print('Reordered columns using sample_submission.csv')\n",
        "    # except Exception:\n",
        "    #     print('sample_submission.csv not found – using inverse-transformed class order')\n",
        "\n",
        "    submission.to_csv('Submission.csv', index=False)\n",
        "    print('Submission.csv generated (probabilities)')\n",
        "    print(submission.head())"
      ],
      "metadata": {
        "id": "IQ7AtIhCQ5aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SUBMIT_LABELS:\n",
        "    # • For accuracy / precision → use model.predict()\n",
        "\n",
        "    y_pred_labels = label_encoder.inverse_transform(y_pred_labels_enc)\n",
        "\n",
        "    labels_df = pd.DataFrame({\n",
        "        ID_COL: test_df[ID_COL],\n",
        "        f'{TARGET_COL}': y_pred_labels\n",
        "    })\n",
        "\n",
        "    labels_df.to_csv('Submission_labels.csv', index=False)\n",
        "    print('Submission_labels.csv generated (labels)')\n",
        ""
      ],
      "metadata": {
        "id": "UNsKD_qvQ6gr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}